{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae905c60-4686-43c2-9ead-87c8cf8086d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9417c761-c97c-404b-8eee-55819fb66d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load surprisal data from CSV\n",
    "def load_surprisal_data(language):\n",
    "    file_path = f\"results/surprisal_wav2vec_lm/{language}_surprisal_data_wav2vec_golos.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.rename(columns={'Surprisal Data': 'Surprisal Data Wav2vec'}, inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "\n",
    "def load_surprisal_data_whisper(language):\n",
    "    file_path = f\"results/surprisal_whisper_medium_ru/{language}_surprisal_data_whisper_medium_ru.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df =  pd.read_csv(file_path)\n",
    "        df.rename(columns={'Surprisal Data': 'Surprisal Data Whisper'}, inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "        \n",
    "def open_dataframe(language, folder_path=\"results/intelligibility/\"):\n",
    "    file_name = f\"{folder_path}{language}_average_results.csv\"\n",
    "    file_name_correct = f\"{folder_path}{language}_average_results_correct.csv\"\n",
    "\n",
    "    # Load original and corrected results\n",
    "    df = pd.read_csv(file_name)\n",
    "    #df_correct = pd.read_csv(file_name_correct)\n",
    "    # Merge dataframes on 'source_text_to_be_translated'\n",
    "    #df = pd.merge(df, df_correct[['source_text_to_be_translated', 'user_free_translation_time_taken']], on='source_text_to_be_translated', suffixes=('', '_correct'), how='left')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load distances\n",
    "def open_variables(language):\n",
    "    file_name = \"data/all_variables.csv\"\n",
    "    df = pd.read_csv(file_name)\n",
    "    df = df[df['language'] == language]\n",
    "    df.rename(columns={'source_text_to_be_translated': 'Expression L2'}, inplace=True)\n",
    "    df.drop(columns = ['model_gpt_small_avg_surprisal_phrase_ru', 'model_gpt_small_avg_surprisal_literal', 'model_gpt_small_avg_surprisal_phrase_l2','model_gpt_large_avg_surprisal_phrase_ru', 'model_gpt_large_avg_surprisal_literal', 'model_gpt_large_avg_surprisal_phrase_l2', 'correct_percentage_mcq','language',\t'correct_percentage_free',\t'average_time_free', 'average_time_mcq'], inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1afc3275-ac33-43af-a215-000064dcc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"BE\", \"BG\", \"CS\", \"UK\", \"PL\"]\n",
    "surprisal_golos = dict()\n",
    "surprisal_whisper = dict()\n",
    "combined_data = dict()\n",
    "distance_variables = dict()\n",
    "experiment_results = dict()\n",
    "for language in languages:\n",
    "    surprisal_golos[language] = load_surprisal_data(language)\n",
    "    surprisal_golos[language] = load_surprisal_data(language)\n",
    "    surprisal_whisper[language] = load_surprisal_data_whisper(language)\n",
    "    distance_variables[language] = open_variables(language)\n",
    "    experiment_results[language] = open_dataframe(language)\n",
    "    experiment_results[language].columns = ['Expression L2','user_free_translation_time_taken',\t'user_mcq_translation_time_taken', 'accuracy_mcq', 'accuracy_free']#, 'free_translation_time_correct']\n",
    "    combined_df = pd.merge(experiment_results[language], surprisal_golos[language], on='Expression L2', how='inner')\n",
    "    combined_df = pd.merge(combined_df, surprisal_whisper[language], on='Expression L2', how='inner')\n",
    "    combined_df = pd.merge(combined_df, distance_variables[language], on='Expression L2', how='inner')\n",
    "    combined_data[language] = combined_df\n",
    "    combined_data['all'] = pd.concat(list(combined_data.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "36bbb14c-8b5e-4cc0-8838-ce50c7923ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expression L2</th>\n",
       "      <th>user_free_translation_time_taken</th>\n",
       "      <th>user_mcq_translation_time_taken</th>\n",
       "      <th>accuracy_mcq</th>\n",
       "      <th>accuracy_free</th>\n",
       "      <th>audio_number_x</th>\n",
       "      <th>Expression RU_x</th>\n",
       "      <th>Sentence_x</th>\n",
       "      <th>Surprisal Data Wav2vec</th>\n",
       "      <th>audio_number_y</th>\n",
       "      <th>...</th>\n",
       "      <th>was_fixed</th>\n",
       "      <th>pwld_literal</th>\n",
       "      <th>pwld_fixed</th>\n",
       "      <th>RU</th>\n",
       "      <th>model_bert_small_avg_surprisal_phrase_ru</th>\n",
       "      <th>model_bert_small_avg_surprisal_literal</th>\n",
       "      <th>model_bert_small_avg_surprisal_phrase_l2</th>\n",
       "      <th>model_bert_large_avg_surprisal_phrase_ru</th>\n",
       "      <th>model_bert_large_avg_surprisal_literal</th>\n",
       "      <th>model_bert_large_avg_surprisal_phrase_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>а то і</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.055556</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>16</td>\n",
       "      <td>а то и</td>\n",
       "      <td>яна не верыць мне і думае, што яе пакараюць не...</td>\n",
       "      <td>14.011767</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.205246</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>0.326316</td>\n",
       "      <td>а то и</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.995531</td>\n",
       "      <td>6.530054</td>\n",
       "      <td>0.848966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ад таго што</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>7.277778</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>20</td>\n",
       "      <td>оттого что</td>\n",
       "      <td>прачнуўшыся ад таго, што мяне тармасіла лі-лі,...</td>\n",
       "      <td>13.971160</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.886588</td>\n",
       "      <td>0.239234</td>\n",
       "      <td>0.194079</td>\n",
       "      <td>оттого что</td>\n",
       "      <td>15.579988</td>\n",
       "      <td>12.436823</td>\n",
       "      <td>15.687457</td>\n",
       "      <td>0.066178</td>\n",
       "      <td>3.524041</td>\n",
       "      <td>0.237431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>адным словам</td>\n",
       "      <td>11.458333</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>33</td>\n",
       "      <td>одним словом</td>\n",
       "      <td>адным словам, пад мінскам есць такая спецыяльн...</td>\n",
       "      <td>14.645604</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>3.469444</td>\n",
       "      <td>0.064593</td>\n",
       "      <td>0.064593</td>\n",
       "      <td>одним словом</td>\n",
       "      <td>19.848414</td>\n",
       "      <td>20.621407</td>\n",
       "      <td>23.131944</td>\n",
       "      <td>0.964844</td>\n",
       "      <td>6.163736</td>\n",
       "      <td>7.806912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>але не</td>\n",
       "      <td>10.277778</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>19</td>\n",
       "      <td>хотя и</td>\n",
       "      <td>тыгр здольны лазіць (але не так добра).</td>\n",
       "      <td>14.394813</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>3.191823</td>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>хотя и</td>\n",
       "      <td>20.307293</td>\n",
       "      <td>16.877299</td>\n",
       "      <td>16.842264</td>\n",
       "      <td>0.132899</td>\n",
       "      <td>8.756669</td>\n",
       "      <td>4.283575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>амаль што</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>45</td>\n",
       "      <td>почти что</td>\n",
       "      <td>яна разумела і нават апраўдвала, калі на гэта ...</td>\n",
       "      <td>13.747244</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>2.962412</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.279605</td>\n",
       "      <td>почти что</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.144357</td>\n",
       "      <td>4.558953</td>\n",
       "      <td>2.045249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>więc jednak</td>\n",
       "      <td>14.136364</td>\n",
       "      <td>7.090909</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>все же</td>\n",
       "      <td>odróżnia nas... tak..., więc jednak</td>\n",
       "      <td>13.972869</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>3.485034</td>\n",
       "      <td>0.283626</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>все же</td>\n",
       "      <td>18.476286</td>\n",
       "      <td>17.221178</td>\n",
       "      <td>34.307155</td>\n",
       "      <td>9.139466</td>\n",
       "      <td>11.092093</td>\n",
       "      <td>9.528961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>wszystko jedno</td>\n",
       "      <td>22.705882</td>\n",
       "      <td>7.705882</td>\n",
       "      <td>64.705882</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>2</td>\n",
       "      <td>все равно</td>\n",
       "      <td>zamieszanie potęgował fakt, że niektórzy zacho...</td>\n",
       "      <td>11.729475</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.696618</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.351974</td>\n",
       "      <td>все равно</td>\n",
       "      <td>19.194976</td>\n",
       "      <td>15.263934</td>\n",
       "      <td>38.355094</td>\n",
       "      <td>0.150975</td>\n",
       "      <td>4.155643</td>\n",
       "      <td>4.545707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>wygląda na to</td>\n",
       "      <td>17.466667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>35</td>\n",
       "      <td>судя по всему</td>\n",
       "      <td>wygląda na to, że lubimy takie pochwały.</td>\n",
       "      <td>12.576071</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>3.130294</td>\n",
       "      <td>0.260526</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>судя по всему</td>\n",
       "      <td>18.350241</td>\n",
       "      <td>23.179404</td>\n",
       "      <td>23.558151</td>\n",
       "      <td>0.286702</td>\n",
       "      <td>4.019640</td>\n",
       "      <td>9.612821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>z tego że</td>\n",
       "      <td>13.652174</td>\n",
       "      <td>5.347826</td>\n",
       "      <td>34.782609</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>20</td>\n",
       "      <td>оттого что</td>\n",
       "      <td>pomiędzy nią a resztą pracowników nastąpiła kr...</td>\n",
       "      <td>9.950880</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>3.392154</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>0.177632</td>\n",
       "      <td>оттого что</td>\n",
       "      <td>21.258415</td>\n",
       "      <td>13.903686</td>\n",
       "      <td>18.277955</td>\n",
       "      <td>1.012232</td>\n",
       "      <td>4.985864</td>\n",
       "      <td>3.013913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>zanim</td>\n",
       "      <td>11.043478</td>\n",
       "      <td>5.086957</td>\n",
       "      <td>34.782609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>прежде чем</td>\n",
       "      <td>zanim się połapią, że to była rozgrywka.</td>\n",
       "      <td>12.550552</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>2.619921</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>прежде чем</td>\n",
       "      <td>25.931616</td>\n",
       "      <td>15.029487</td>\n",
       "      <td>28.815857</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>5.268028</td>\n",
       "      <td>16.758480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>880 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Expression L2  user_free_translation_time_taken  \\\n",
       "0           а то і                         12.500000   \n",
       "1      ад таго што                         11.111111   \n",
       "2     адным словам                         11.458333   \n",
       "3           але не                         10.277778   \n",
       "4        амаль што                         11.500000   \n",
       "..             ...                               ...   \n",
       "53     więc jednak                         14.136364   \n",
       "54  wszystko jedno                         22.705882   \n",
       "55   wygląda na to                         17.466667   \n",
       "56       z tego że                         13.652174   \n",
       "57           zanim                         11.043478   \n",
       "\n",
       "    user_mcq_translation_time_taken  accuracy_mcq  accuracy_free  \\\n",
       "0                          4.055556    100.000000      55.555556   \n",
       "1                          7.277778     94.444444      72.222222   \n",
       "2                          5.375000     83.333333      79.166667   \n",
       "3                          5.222222     94.444444      16.666667   \n",
       "4                          5.750000     75.000000      16.666667   \n",
       "..                              ...           ...            ...   \n",
       "53                         7.090909     45.454545       0.000000   \n",
       "54                         7.705882     64.705882      11.764706   \n",
       "55                         5.000000     73.333333      13.333333   \n",
       "56                         5.347826     34.782609       4.347826   \n",
       "57                         5.086957     34.782609       0.000000   \n",
       "\n",
       "    audio_number_x Expression RU_x  \\\n",
       "0               16          а то и   \n",
       "1               20      оттого что   \n",
       "2               33    одним словом   \n",
       "3               19          хотя и   \n",
       "4               45       почти что   \n",
       "..             ...             ...   \n",
       "53              37          все же   \n",
       "54               2       все равно   \n",
       "55              35   судя по всему   \n",
       "56              20      оттого что   \n",
       "57              24      прежде чем   \n",
       "\n",
       "                                           Sentence_x  Surprisal Data Wav2vec  \\\n",
       "0   яна не верыць мне і думае, што яе пакараюць не...               14.011767   \n",
       "1   прачнуўшыся ад таго, што мяне тармасіла лі-лі,...               13.971160   \n",
       "2   адным словам, пад мінскам есць такая спецыяльн...               14.645604   \n",
       "3             тыгр здольны лазіць (але не так добра).               14.394813   \n",
       "4   яна разумела і нават апраўдвала, калі на гэта ...               13.747244   \n",
       "..                                                ...                     ...   \n",
       "53                odróżnia nas... tak..., więc jednak               13.972869   \n",
       "54  zamieszanie potęgował fakt, że niektórzy zacho...               11.729475   \n",
       "55           wygląda na to, że lubimy takie pochwały.               12.576071   \n",
       "56  pomiędzy nią a resztą pracowników nastąpiła kr...                9.950880   \n",
       "57           zanim się połapią, że to była rozgrywka.               12.550552   \n",
       "\n",
       "    audio_number_y  ... was_fixed pwld_literal  pwld_fixed             RU  \\\n",
       "0               16  ...  3.205246     0.363158    0.326316         а то и   \n",
       "1               20  ...  2.886588     0.239234    0.194079     оттого что   \n",
       "2               33  ...  3.469444     0.064593    0.064593   одним словом   \n",
       "3               19  ...  3.191823     0.284211    0.324561         хотя и   \n",
       "4               45  ...  2.962412     0.236842    0.279605      почти что   \n",
       "..             ...  ...       ...          ...         ...            ...   \n",
       "53              37  ...  3.485034     0.283626    0.652632         все же   \n",
       "54               2  ...  3.696618     0.406015    0.351974      все равно   \n",
       "55              35  ...  3.130294     0.260526    0.291866  судя по всему   \n",
       "56              20  ...  3.392154     0.075658    0.177632     оттого что   \n",
       "57              24  ...  2.619921     0.026316    0.280702     прежде чем   \n",
       "\n",
       "    model_bert_small_avg_surprisal_phrase_ru  \\\n",
       "0                                   0.000000   \n",
       "1                                  15.579988   \n",
       "2                                  19.848414   \n",
       "3                                  20.307293   \n",
       "4                                   0.000000   \n",
       "..                                       ...   \n",
       "53                                 18.476286   \n",
       "54                                 19.194976   \n",
       "55                                 18.350241   \n",
       "56                                 21.258415   \n",
       "57                                 25.931616   \n",
       "\n",
       "    model_bert_small_avg_surprisal_literal  \\\n",
       "0                                 0.000000   \n",
       "1                                12.436823   \n",
       "2                                20.621407   \n",
       "3                                16.877299   \n",
       "4                                 0.000000   \n",
       "..                                     ...   \n",
       "53                               17.221178   \n",
       "54                               15.263934   \n",
       "55                               23.179404   \n",
       "56                               13.903686   \n",
       "57                               15.029487   \n",
       "\n",
       "    model_bert_small_avg_surprisal_phrase_l2  \\\n",
       "0                                   0.000000   \n",
       "1                                  15.687457   \n",
       "2                                  23.131944   \n",
       "3                                  16.842264   \n",
       "4                                   0.000000   \n",
       "..                                       ...   \n",
       "53                                 34.307155   \n",
       "54                                 38.355094   \n",
       "55                                 23.558151   \n",
       "56                                 18.277955   \n",
       "57                                 28.815857   \n",
       "\n",
       "   model_bert_large_avg_surprisal_phrase_ru  \\\n",
       "0                                  1.995531   \n",
       "1                                  0.066178   \n",
       "2                                  0.964844   \n",
       "3                                  0.132899   \n",
       "4                                  4.144357   \n",
       "..                                      ...   \n",
       "53                                 9.139466   \n",
       "54                                 0.150975   \n",
       "55                                 0.286702   \n",
       "56                                 1.012232   \n",
       "57                                 0.005989   \n",
       "\n",
       "    model_bert_large_avg_surprisal_literal  \\\n",
       "0                                 6.530054   \n",
       "1                                 3.524041   \n",
       "2                                 6.163736   \n",
       "3                                 8.756669   \n",
       "4                                 4.558953   \n",
       "..                                     ...   \n",
       "53                               11.092093   \n",
       "54                                4.155643   \n",
       "55                                4.019640   \n",
       "56                                4.985864   \n",
       "57                                5.268028   \n",
       "\n",
       "    model_bert_large_avg_surprisal_phrase_l2  \n",
       "0                                   0.848966  \n",
       "1                                   0.237431  \n",
       "2                                   7.806912  \n",
       "3                                   4.283575  \n",
       "4                                   2.045249  \n",
       "..                                       ...  \n",
       "53                                  9.528961  \n",
       "54                                  4.545707  \n",
       "55                                  9.612821  \n",
       "56                                  3.013913  \n",
       "57                                 16.758480  \n",
       "\n",
       "[880 rows x 24 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "329df38b-26f8-4b4c-82ac-8c5eb9d926c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6r_4f6n16dv6s41vfjb0rqzc0000gn/T/ipykernel_6127/1260891350.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  combined_data['all'].corr()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_free_translation_time_taken</th>\n",
       "      <th>user_mcq_translation_time_taken</th>\n",
       "      <th>accuracy_mcq</th>\n",
       "      <th>accuracy_free</th>\n",
       "      <th>audio_number_x</th>\n",
       "      <th>Surprisal Data Wav2vec</th>\n",
       "      <th>audio_number_y</th>\n",
       "      <th>Surprisal Data Whisper</th>\n",
       "      <th>was_literal</th>\n",
       "      <th>was_fixed</th>\n",
       "      <th>pwld_literal</th>\n",
       "      <th>pwld_fixed</th>\n",
       "      <th>model_bert_small_avg_surprisal_phrase_ru</th>\n",
       "      <th>model_bert_small_avg_surprisal_literal</th>\n",
       "      <th>model_bert_small_avg_surprisal_phrase_l2</th>\n",
       "      <th>model_bert_large_avg_surprisal_phrase_ru</th>\n",
       "      <th>model_bert_large_avg_surprisal_literal</th>\n",
       "      <th>model_bert_large_avg_surprisal_phrase_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_free_translation_time_taken</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464914</td>\n",
       "      <td>-0.053324</td>\n",
       "      <td>-0.283384</td>\n",
       "      <td>0.035510</td>\n",
       "      <td>-0.326742</td>\n",
       "      <td>0.035510</td>\n",
       "      <td>-0.005482</td>\n",
       "      <td>0.077187</td>\n",
       "      <td>0.072446</td>\n",
       "      <td>0.070323</td>\n",
       "      <td>0.208050</td>\n",
       "      <td>-0.058121</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>-0.055826</td>\n",
       "      <td>-0.010111</td>\n",
       "      <td>0.025385</td>\n",
       "      <td>0.097075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_mcq_translation_time_taken</th>\n",
       "      <td>0.464914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.328870</td>\n",
       "      <td>-0.467291</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>-0.308439</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.021579</td>\n",
       "      <td>0.118188</td>\n",
       "      <td>-0.013939</td>\n",
       "      <td>0.244972</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.036619</td>\n",
       "      <td>0.096071</td>\n",
       "      <td>0.104092</td>\n",
       "      <td>0.091504</td>\n",
       "      <td>0.278210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_mcq</th>\n",
       "      <td>-0.053324</td>\n",
       "      <td>-0.328870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470072</td>\n",
       "      <td>-0.044590</td>\n",
       "      <td>0.399195</td>\n",
       "      <td>-0.044590</td>\n",
       "      <td>0.193176</td>\n",
       "      <td>-0.107377</td>\n",
       "      <td>-0.259190</td>\n",
       "      <td>0.158943</td>\n",
       "      <td>-0.414800</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>-0.150123</td>\n",
       "      <td>-0.034947</td>\n",
       "      <td>0.103829</td>\n",
       "      <td>-0.225560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_free</th>\n",
       "      <td>-0.283384</td>\n",
       "      <td>-0.467291</td>\n",
       "      <td>0.470072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064515</td>\n",
       "      <td>0.404457</td>\n",
       "      <td>-0.064515</td>\n",
       "      <td>0.222628</td>\n",
       "      <td>-0.082167</td>\n",
       "      <td>-0.178237</td>\n",
       "      <td>-0.013643</td>\n",
       "      <td>-0.403207</td>\n",
       "      <td>-0.064425</td>\n",
       "      <td>-0.123663</td>\n",
       "      <td>-0.080080</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>-0.199954</td>\n",
       "      <td>-0.385670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_number_x</th>\n",
       "      <td>0.035510</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>-0.044590</td>\n",
       "      <td>-0.064515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.070632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033920</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.074562</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>-0.063493</td>\n",
       "      <td>-0.051453</td>\n",
       "      <td>-0.033262</td>\n",
       "      <td>-0.050743</td>\n",
       "      <td>-0.059808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surprisal Data Wav2vec</th>\n",
       "      <td>-0.326742</td>\n",
       "      <td>-0.308439</td>\n",
       "      <td>0.399195</td>\n",
       "      <td>0.404457</td>\n",
       "      <td>-0.070632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.070632</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>-0.064883</td>\n",
       "      <td>-0.052357</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>-0.190831</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>-0.037253</td>\n",
       "      <td>-0.103259</td>\n",
       "      <td>-0.039129</td>\n",
       "      <td>-0.057149</td>\n",
       "      <td>-0.363981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_number_y</th>\n",
       "      <td>0.035510</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>-0.044590</td>\n",
       "      <td>-0.064515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.070632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033920</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>0.074562</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>-0.063493</td>\n",
       "      <td>-0.051453</td>\n",
       "      <td>-0.033262</td>\n",
       "      <td>-0.050743</td>\n",
       "      <td>-0.059808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surprisal Data Whisper</th>\n",
       "      <td>-0.005482</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>0.193176</td>\n",
       "      <td>0.222628</td>\n",
       "      <td>-0.033920</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>-0.033920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008907</td>\n",
       "      <td>-0.101063</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>-0.162348</td>\n",
       "      <td>-0.021327</td>\n",
       "      <td>-0.114212</td>\n",
       "      <td>-0.086869</td>\n",
       "      <td>0.070268</td>\n",
       "      <td>-0.052651</td>\n",
       "      <td>-0.064881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was_literal</th>\n",
       "      <td>0.077187</td>\n",
       "      <td>-0.021579</td>\n",
       "      <td>-0.107377</td>\n",
       "      <td>-0.082167</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>-0.064883</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>-0.008907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285429</td>\n",
       "      <td>0.123856</td>\n",
       "      <td>0.083033</td>\n",
       "      <td>-0.005796</td>\n",
       "      <td>-0.031906</td>\n",
       "      <td>0.087457</td>\n",
       "      <td>0.030524</td>\n",
       "      <td>-0.038752</td>\n",
       "      <td>-0.028742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was_fixed</th>\n",
       "      <td>0.072446</td>\n",
       "      <td>0.118188</td>\n",
       "      <td>-0.259190</td>\n",
       "      <td>-0.178237</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>-0.052357</td>\n",
       "      <td>0.123456</td>\n",
       "      <td>-0.101063</td>\n",
       "      <td>0.285429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031323</td>\n",
       "      <td>0.377947</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.097139</td>\n",
       "      <td>0.075431</td>\n",
       "      <td>-0.111751</td>\n",
       "      <td>-0.032485</td>\n",
       "      <td>0.058116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwld_literal</th>\n",
       "      <td>0.070323</td>\n",
       "      <td>-0.013939</td>\n",
       "      <td>0.158943</td>\n",
       "      <td>-0.013643</td>\n",
       "      <td>0.074562</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>0.074562</td>\n",
       "      <td>0.052247</td>\n",
       "      <td>0.123856</td>\n",
       "      <td>0.031323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.119843</td>\n",
       "      <td>-0.097048</td>\n",
       "      <td>-0.099639</td>\n",
       "      <td>-0.032623</td>\n",
       "      <td>0.034521</td>\n",
       "      <td>-0.048024</td>\n",
       "      <td>-0.074360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pwld_fixed</th>\n",
       "      <td>0.208050</td>\n",
       "      <td>0.244972</td>\n",
       "      <td>-0.414800</td>\n",
       "      <td>-0.403207</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>-0.190831</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>-0.162348</td>\n",
       "      <td>0.083033</td>\n",
       "      <td>0.377947</td>\n",
       "      <td>0.119843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121324</td>\n",
       "      <td>0.030872</td>\n",
       "      <td>0.046069</td>\n",
       "      <td>-0.050295</td>\n",
       "      <td>0.015413</td>\n",
       "      <td>0.129326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_bert_small_avg_surprisal_phrase_ru</th>\n",
       "      <td>-0.058121</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>-0.064425</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>-0.021327</td>\n",
       "      <td>-0.005796</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>-0.097048</td>\n",
       "      <td>-0.121324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617988</td>\n",
       "      <td>0.351240</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>0.010992</td>\n",
       "      <td>0.135788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_bert_small_avg_surprisal_literal</th>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.036619</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>-0.123663</td>\n",
       "      <td>-0.063493</td>\n",
       "      <td>-0.037253</td>\n",
       "      <td>-0.063493</td>\n",
       "      <td>-0.114212</td>\n",
       "      <td>-0.031906</td>\n",
       "      <td>0.097139</td>\n",
       "      <td>-0.099639</td>\n",
       "      <td>0.030872</td>\n",
       "      <td>0.617988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315492</td>\n",
       "      <td>-0.002914</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>0.200695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_bert_small_avg_surprisal_phrase_l2</th>\n",
       "      <td>-0.055826</td>\n",
       "      <td>0.096071</td>\n",
       "      <td>-0.150123</td>\n",
       "      <td>-0.080080</td>\n",
       "      <td>-0.051453</td>\n",
       "      <td>-0.103259</td>\n",
       "      <td>-0.051453</td>\n",
       "      <td>-0.086869</td>\n",
       "      <td>0.087457</td>\n",
       "      <td>0.075431</td>\n",
       "      <td>-0.032623</td>\n",
       "      <td>0.046069</td>\n",
       "      <td>0.351240</td>\n",
       "      <td>0.315492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145727</td>\n",
       "      <td>0.166172</td>\n",
       "      <td>0.375777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_bert_large_avg_surprisal_phrase_ru</th>\n",
       "      <td>-0.010111</td>\n",
       "      <td>0.104092</td>\n",
       "      <td>-0.034947</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>-0.033262</td>\n",
       "      <td>-0.039129</td>\n",
       "      <td>-0.033262</td>\n",
       "      <td>0.070268</td>\n",
       "      <td>0.030524</td>\n",
       "      <td>-0.111751</td>\n",
       "      <td>0.034521</td>\n",
       "      <td>-0.050295</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>-0.002914</td>\n",
       "      <td>0.145727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170684</td>\n",
       "      <td>0.210701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_bert_large_avg_surprisal_literal</th>\n",
       "      <td>0.025385</td>\n",
       "      <td>0.091504</td>\n",
       "      <td>0.103829</td>\n",
       "      <td>-0.199954</td>\n",
       "      <td>-0.050743</td>\n",
       "      <td>-0.057149</td>\n",
       "      <td>-0.050743</td>\n",
       "      <td>-0.052651</td>\n",
       "      <td>-0.038752</td>\n",
       "      <td>-0.032485</td>\n",
       "      <td>-0.048024</td>\n",
       "      <td>0.015413</td>\n",
       "      <td>0.010992</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>0.166172</td>\n",
       "      <td>0.170684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_bert_large_avg_surprisal_phrase_l2</th>\n",
       "      <td>0.097075</td>\n",
       "      <td>0.278210</td>\n",
       "      <td>-0.225560</td>\n",
       "      <td>-0.385670</td>\n",
       "      <td>-0.059808</td>\n",
       "      <td>-0.363981</td>\n",
       "      <td>-0.059808</td>\n",
       "      <td>-0.064881</td>\n",
       "      <td>-0.028742</td>\n",
       "      <td>0.058116</td>\n",
       "      <td>-0.074360</td>\n",
       "      <td>0.129326</td>\n",
       "      <td>0.135788</td>\n",
       "      <td>0.200695</td>\n",
       "      <td>0.375777</td>\n",
       "      <td>0.210701</td>\n",
       "      <td>0.258379</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_free_translation_time_taken  \\\n",
       "user_free_translation_time_taken                                  1.000000   \n",
       "user_mcq_translation_time_taken                                   0.464914   \n",
       "accuracy_mcq                                                     -0.053324   \n",
       "accuracy_free                                                    -0.283384   \n",
       "audio_number_x                                                    0.035510   \n",
       "Surprisal Data Wav2vec                                           -0.326742   \n",
       "audio_number_y                                                    0.035510   \n",
       "Surprisal Data Whisper                                           -0.005482   \n",
       "was_literal                                                       0.077187   \n",
       "was_fixed                                                         0.072446   \n",
       "pwld_literal                                                      0.070323   \n",
       "pwld_fixed                                                        0.208050   \n",
       "model_bert_small_avg_surprisal_phrase_ru                         -0.058121   \n",
       "model_bert_small_avg_surprisal_literal                            0.010610   \n",
       "model_bert_small_avg_surprisal_phrase_l2                         -0.055826   \n",
       "model_bert_large_avg_surprisal_phrase_ru                         -0.010111   \n",
       "model_bert_large_avg_surprisal_literal                            0.025385   \n",
       "model_bert_large_avg_surprisal_phrase_l2                          0.097075   \n",
       "\n",
       "                                          user_mcq_translation_time_taken  \\\n",
       "user_free_translation_time_taken                                 0.464914   \n",
       "user_mcq_translation_time_taken                                  1.000000   \n",
       "accuracy_mcq                                                    -0.328870   \n",
       "accuracy_free                                                   -0.467291   \n",
       "audio_number_x                                                   0.002201   \n",
       "Surprisal Data Wav2vec                                          -0.308439   \n",
       "audio_number_y                                                   0.002201   \n",
       "Surprisal Data Whisper                                          -0.000748   \n",
       "was_literal                                                     -0.021579   \n",
       "was_fixed                                                        0.118188   \n",
       "pwld_literal                                                    -0.013939   \n",
       "pwld_fixed                                                       0.244972   \n",
       "model_bert_small_avg_surprisal_phrase_ru                         0.004526   \n",
       "model_bert_small_avg_surprisal_literal                           0.036619   \n",
       "model_bert_small_avg_surprisal_phrase_l2                         0.096071   \n",
       "model_bert_large_avg_surprisal_phrase_ru                         0.104092   \n",
       "model_bert_large_avg_surprisal_literal                           0.091504   \n",
       "model_bert_large_avg_surprisal_phrase_l2                         0.278210   \n",
       "\n",
       "                                          accuracy_mcq  accuracy_free  \\\n",
       "user_free_translation_time_taken             -0.053324      -0.283384   \n",
       "user_mcq_translation_time_taken              -0.328870      -0.467291   \n",
       "accuracy_mcq                                  1.000000       0.470072   \n",
       "accuracy_free                                 0.470072       1.000000   \n",
       "audio_number_x                               -0.044590      -0.064515   \n",
       "Surprisal Data Wav2vec                        0.399195       0.404457   \n",
       "audio_number_y                               -0.044590      -0.064515   \n",
       "Surprisal Data Whisper                        0.193176       0.222628   \n",
       "was_literal                                  -0.107377      -0.082167   \n",
       "was_fixed                                    -0.259190      -0.178237   \n",
       "pwld_literal                                  0.158943      -0.013643   \n",
       "pwld_fixed                                   -0.414800      -0.403207   \n",
       "model_bert_small_avg_surprisal_phrase_ru      0.012436      -0.064425   \n",
       "model_bert_small_avg_surprisal_literal        0.006003      -0.123663   \n",
       "model_bert_small_avg_surprisal_phrase_l2     -0.150123      -0.080080   \n",
       "model_bert_large_avg_surprisal_phrase_ru     -0.034947      -0.003925   \n",
       "model_bert_large_avg_surprisal_literal        0.103829      -0.199954   \n",
       "model_bert_large_avg_surprisal_phrase_l2     -0.225560      -0.385670   \n",
       "\n",
       "                                          audio_number_x  \\\n",
       "user_free_translation_time_taken                0.035510   \n",
       "user_mcq_translation_time_taken                 0.002201   \n",
       "accuracy_mcq                                   -0.044590   \n",
       "accuracy_free                                  -0.064515   \n",
       "audio_number_x                                  1.000000   \n",
       "Surprisal Data Wav2vec                         -0.070632   \n",
       "audio_number_y                                  1.000000   \n",
       "Surprisal Data Whisper                         -0.033920   \n",
       "was_literal                                     0.014985   \n",
       "was_fixed                                       0.123456   \n",
       "pwld_literal                                    0.074562   \n",
       "pwld_fixed                                      0.074945   \n",
       "model_bert_small_avg_surprisal_phrase_ru        0.007207   \n",
       "model_bert_small_avg_surprisal_literal         -0.063493   \n",
       "model_bert_small_avg_surprisal_phrase_l2       -0.051453   \n",
       "model_bert_large_avg_surprisal_phrase_ru       -0.033262   \n",
       "model_bert_large_avg_surprisal_literal         -0.050743   \n",
       "model_bert_large_avg_surprisal_phrase_l2       -0.059808   \n",
       "\n",
       "                                          Surprisal Data Wav2vec  \\\n",
       "user_free_translation_time_taken                       -0.326742   \n",
       "user_mcq_translation_time_taken                        -0.308439   \n",
       "accuracy_mcq                                            0.399195   \n",
       "accuracy_free                                           0.404457   \n",
       "audio_number_x                                         -0.070632   \n",
       "Surprisal Data Wav2vec                                  1.000000   \n",
       "audio_number_y                                         -0.070632   \n",
       "Surprisal Data Whisper                                  0.029189   \n",
       "was_literal                                            -0.064883   \n",
       "was_fixed                                              -0.052357   \n",
       "pwld_literal                                            0.024212   \n",
       "pwld_fixed                                             -0.190831   \n",
       "model_bert_small_avg_surprisal_phrase_ru                0.015014   \n",
       "model_bert_small_avg_surprisal_literal                 -0.037253   \n",
       "model_bert_small_avg_surprisal_phrase_l2               -0.103259   \n",
       "model_bert_large_avg_surprisal_phrase_ru               -0.039129   \n",
       "model_bert_large_avg_surprisal_literal                 -0.057149   \n",
       "model_bert_large_avg_surprisal_phrase_l2               -0.363981   \n",
       "\n",
       "                                          audio_number_y  \\\n",
       "user_free_translation_time_taken                0.035510   \n",
       "user_mcq_translation_time_taken                 0.002201   \n",
       "accuracy_mcq                                   -0.044590   \n",
       "accuracy_free                                  -0.064515   \n",
       "audio_number_x                                  1.000000   \n",
       "Surprisal Data Wav2vec                         -0.070632   \n",
       "audio_number_y                                  1.000000   \n",
       "Surprisal Data Whisper                         -0.033920   \n",
       "was_literal                                     0.014985   \n",
       "was_fixed                                       0.123456   \n",
       "pwld_literal                                    0.074562   \n",
       "pwld_fixed                                      0.074945   \n",
       "model_bert_small_avg_surprisal_phrase_ru        0.007207   \n",
       "model_bert_small_avg_surprisal_literal         -0.063493   \n",
       "model_bert_small_avg_surprisal_phrase_l2       -0.051453   \n",
       "model_bert_large_avg_surprisal_phrase_ru       -0.033262   \n",
       "model_bert_large_avg_surprisal_literal         -0.050743   \n",
       "model_bert_large_avg_surprisal_phrase_l2       -0.059808   \n",
       "\n",
       "                                          Surprisal Data Whisper  was_literal  \\\n",
       "user_free_translation_time_taken                       -0.005482     0.077187   \n",
       "user_mcq_translation_time_taken                        -0.000748    -0.021579   \n",
       "accuracy_mcq                                            0.193176    -0.107377   \n",
       "accuracy_free                                           0.222628    -0.082167   \n",
       "audio_number_x                                         -0.033920     0.014985   \n",
       "Surprisal Data Wav2vec                                  0.029189    -0.064883   \n",
       "audio_number_y                                         -0.033920     0.014985   \n",
       "Surprisal Data Whisper                                  1.000000    -0.008907   \n",
       "was_literal                                            -0.008907     1.000000   \n",
       "was_fixed                                              -0.101063     0.285429   \n",
       "pwld_literal                                            0.052247     0.123856   \n",
       "pwld_fixed                                             -0.162348     0.083033   \n",
       "model_bert_small_avg_surprisal_phrase_ru               -0.021327    -0.005796   \n",
       "model_bert_small_avg_surprisal_literal                 -0.114212    -0.031906   \n",
       "model_bert_small_avg_surprisal_phrase_l2               -0.086869     0.087457   \n",
       "model_bert_large_avg_surprisal_phrase_ru                0.070268     0.030524   \n",
       "model_bert_large_avg_surprisal_literal                 -0.052651    -0.038752   \n",
       "model_bert_large_avg_surprisal_phrase_l2               -0.064881    -0.028742   \n",
       "\n",
       "                                          was_fixed  pwld_literal  pwld_fixed  \\\n",
       "user_free_translation_time_taken           0.072446      0.070323    0.208050   \n",
       "user_mcq_translation_time_taken            0.118188     -0.013939    0.244972   \n",
       "accuracy_mcq                              -0.259190      0.158943   -0.414800   \n",
       "accuracy_free                             -0.178237     -0.013643   -0.403207   \n",
       "audio_number_x                             0.123456      0.074562    0.074945   \n",
       "Surprisal Data Wav2vec                    -0.052357      0.024212   -0.190831   \n",
       "audio_number_y                             0.123456      0.074562    0.074945   \n",
       "Surprisal Data Whisper                    -0.101063      0.052247   -0.162348   \n",
       "was_literal                                0.285429      0.123856    0.083033   \n",
       "was_fixed                                  1.000000      0.031323    0.377947   \n",
       "pwld_literal                               0.031323      1.000000    0.119843   \n",
       "pwld_fixed                                 0.377947      0.119843    1.000000   \n",
       "model_bert_small_avg_surprisal_phrase_ru   0.013072     -0.097048   -0.121324   \n",
       "model_bert_small_avg_surprisal_literal     0.097139     -0.099639    0.030872   \n",
       "model_bert_small_avg_surprisal_phrase_l2   0.075431     -0.032623    0.046069   \n",
       "model_bert_large_avg_surprisal_phrase_ru  -0.111751      0.034521   -0.050295   \n",
       "model_bert_large_avg_surprisal_literal    -0.032485     -0.048024    0.015413   \n",
       "model_bert_large_avg_surprisal_phrase_l2   0.058116     -0.074360    0.129326   \n",
       "\n",
       "                                          model_bert_small_avg_surprisal_phrase_ru  \\\n",
       "user_free_translation_time_taken                                         -0.058121   \n",
       "user_mcq_translation_time_taken                                           0.004526   \n",
       "accuracy_mcq                                                              0.012436   \n",
       "accuracy_free                                                            -0.064425   \n",
       "audio_number_x                                                            0.007207   \n",
       "Surprisal Data Wav2vec                                                    0.015014   \n",
       "audio_number_y                                                            0.007207   \n",
       "Surprisal Data Whisper                                                   -0.021327   \n",
       "was_literal                                                              -0.005796   \n",
       "was_fixed                                                                 0.013072   \n",
       "pwld_literal                                                             -0.097048   \n",
       "pwld_fixed                                                               -0.121324   \n",
       "model_bert_small_avg_surprisal_phrase_ru                                  1.000000   \n",
       "model_bert_small_avg_surprisal_literal                                    0.617988   \n",
       "model_bert_small_avg_surprisal_phrase_l2                                  0.351240   \n",
       "model_bert_large_avg_surprisal_phrase_ru                                  0.060623   \n",
       "model_bert_large_avg_surprisal_literal                                    0.010992   \n",
       "model_bert_large_avg_surprisal_phrase_l2                                  0.135788   \n",
       "\n",
       "                                          model_bert_small_avg_surprisal_literal  \\\n",
       "user_free_translation_time_taken                                        0.010610   \n",
       "user_mcq_translation_time_taken                                         0.036619   \n",
       "accuracy_mcq                                                            0.006003   \n",
       "accuracy_free                                                          -0.123663   \n",
       "audio_number_x                                                         -0.063493   \n",
       "Surprisal Data Wav2vec                                                 -0.037253   \n",
       "audio_number_y                                                         -0.063493   \n",
       "Surprisal Data Whisper                                                 -0.114212   \n",
       "was_literal                                                            -0.031906   \n",
       "was_fixed                                                               0.097139   \n",
       "pwld_literal                                                           -0.099639   \n",
       "pwld_fixed                                                              0.030872   \n",
       "model_bert_small_avg_surprisal_phrase_ru                                0.617988   \n",
       "model_bert_small_avg_surprisal_literal                                  1.000000   \n",
       "model_bert_small_avg_surprisal_phrase_l2                                0.315492   \n",
       "model_bert_large_avg_surprisal_phrase_ru                               -0.002914   \n",
       "model_bert_large_avg_surprisal_literal                                  0.017779   \n",
       "model_bert_large_avg_surprisal_phrase_l2                                0.200695   \n",
       "\n",
       "                                          model_bert_small_avg_surprisal_phrase_l2  \\\n",
       "user_free_translation_time_taken                                         -0.055826   \n",
       "user_mcq_translation_time_taken                                           0.096071   \n",
       "accuracy_mcq                                                             -0.150123   \n",
       "accuracy_free                                                            -0.080080   \n",
       "audio_number_x                                                           -0.051453   \n",
       "Surprisal Data Wav2vec                                                   -0.103259   \n",
       "audio_number_y                                                           -0.051453   \n",
       "Surprisal Data Whisper                                                   -0.086869   \n",
       "was_literal                                                               0.087457   \n",
       "was_fixed                                                                 0.075431   \n",
       "pwld_literal                                                             -0.032623   \n",
       "pwld_fixed                                                                0.046069   \n",
       "model_bert_small_avg_surprisal_phrase_ru                                  0.351240   \n",
       "model_bert_small_avg_surprisal_literal                                    0.315492   \n",
       "model_bert_small_avg_surprisal_phrase_l2                                  1.000000   \n",
       "model_bert_large_avg_surprisal_phrase_ru                                  0.145727   \n",
       "model_bert_large_avg_surprisal_literal                                    0.166172   \n",
       "model_bert_large_avg_surprisal_phrase_l2                                  0.375777   \n",
       "\n",
       "                                          model_bert_large_avg_surprisal_phrase_ru  \\\n",
       "user_free_translation_time_taken                                         -0.010111   \n",
       "user_mcq_translation_time_taken                                           0.104092   \n",
       "accuracy_mcq                                                             -0.034947   \n",
       "accuracy_free                                                            -0.003925   \n",
       "audio_number_x                                                           -0.033262   \n",
       "Surprisal Data Wav2vec                                                   -0.039129   \n",
       "audio_number_y                                                           -0.033262   \n",
       "Surprisal Data Whisper                                                    0.070268   \n",
       "was_literal                                                               0.030524   \n",
       "was_fixed                                                                -0.111751   \n",
       "pwld_literal                                                              0.034521   \n",
       "pwld_fixed                                                               -0.050295   \n",
       "model_bert_small_avg_surprisal_phrase_ru                                  0.060623   \n",
       "model_bert_small_avg_surprisal_literal                                   -0.002914   \n",
       "model_bert_small_avg_surprisal_phrase_l2                                  0.145727   \n",
       "model_bert_large_avg_surprisal_phrase_ru                                  1.000000   \n",
       "model_bert_large_avg_surprisal_literal                                    0.170684   \n",
       "model_bert_large_avg_surprisal_phrase_l2                                  0.210701   \n",
       "\n",
       "                                          model_bert_large_avg_surprisal_literal  \\\n",
       "user_free_translation_time_taken                                        0.025385   \n",
       "user_mcq_translation_time_taken                                         0.091504   \n",
       "accuracy_mcq                                                            0.103829   \n",
       "accuracy_free                                                          -0.199954   \n",
       "audio_number_x                                                         -0.050743   \n",
       "Surprisal Data Wav2vec                                                 -0.057149   \n",
       "audio_number_y                                                         -0.050743   \n",
       "Surprisal Data Whisper                                                 -0.052651   \n",
       "was_literal                                                            -0.038752   \n",
       "was_fixed                                                              -0.032485   \n",
       "pwld_literal                                                           -0.048024   \n",
       "pwld_fixed                                                              0.015413   \n",
       "model_bert_small_avg_surprisal_phrase_ru                                0.010992   \n",
       "model_bert_small_avg_surprisal_literal                                  0.017779   \n",
       "model_bert_small_avg_surprisal_phrase_l2                                0.166172   \n",
       "model_bert_large_avg_surprisal_phrase_ru                                0.170684   \n",
       "model_bert_large_avg_surprisal_literal                                  1.000000   \n",
       "model_bert_large_avg_surprisal_phrase_l2                                0.258379   \n",
       "\n",
       "                                          model_bert_large_avg_surprisal_phrase_l2  \n",
       "user_free_translation_time_taken                                          0.097075  \n",
       "user_mcq_translation_time_taken                                           0.278210  \n",
       "accuracy_mcq                                                             -0.225560  \n",
       "accuracy_free                                                            -0.385670  \n",
       "audio_number_x                                                           -0.059808  \n",
       "Surprisal Data Wav2vec                                                   -0.363981  \n",
       "audio_number_y                                                           -0.059808  \n",
       "Surprisal Data Whisper                                                   -0.064881  \n",
       "was_literal                                                              -0.028742  \n",
       "was_fixed                                                                 0.058116  \n",
       "pwld_literal                                                             -0.074360  \n",
       "pwld_fixed                                                                0.129326  \n",
       "model_bert_small_avg_surprisal_phrase_ru                                  0.135788  \n",
       "model_bert_small_avg_surprisal_literal                                    0.200695  \n",
       "model_bert_small_avg_surprisal_phrase_l2                                  0.375777  \n",
       "model_bert_large_avg_surprisal_phrase_ru                                  0.210701  \n",
       "model_bert_large_avg_surprisal_literal                                    0.258379  \n",
       "model_bert_large_avg_surprisal_phrase_l2                                  1.000000  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['all'].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33056ff5-b099-4d70-afee-d848ec031ff0",
   "metadata": {},
   "source": [
    "## Below is correlation with distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a4e4be72-ab6d-4fc7-8460-76aecacdf4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6r_4f6n16dv6s41vfjb0rqzc0000gn/T/ipykernel_6127/369574422.py:37: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table.to_latex('correlation_table_all_languages.tex', escape=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# Initialize empty lists to store correlations and p-values\n",
    "corr_ortho_list, p_value_ortho_list = [], []\n",
    "corr_phono_list, p_value_phono_list = [], []\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['accuracy_mcq']\n",
    "    orthographic_distances = df['was_fixed']\n",
    "    phonological_distances = df['pwld_fixed']\n",
    "\n",
    "    # Calculating correlations\n",
    "    corr_ortho, p_value_ortho = pearsonr(orthographic_distances, accuracy_mcq)\n",
    "    corr_phono, p_value_phono = pearsonr(phonological_distances, accuracy_mcq)\n",
    "\n",
    "    # Append results to lists\n",
    "    corr_ortho_list.append(corr_ortho)\n",
    "    p_value_ortho_list.append(p_value_ortho)\n",
    "    corr_phono_list.append(corr_phono)\n",
    "    p_value_phono_list.append(p_value_phono)\n",
    "\n",
    "# Creating a DataFrame with results\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Orthographic Distance': corr_ortho_list,\n",
    "    'Phonological Distance': corr_phono_list,\n",
    "    'p-value (Orthographic)': p_value_ortho_list,\n",
    "    'p-value (Phonological)': p_value_phono_list\n",
    "}, index=list(combined_data.keys()))\n",
    "\n",
    "# Formatting for LaTeX table\n",
    "latex_table = correlation_results.round(3).astype(str)\n",
    "latex_table.to_latex('correlation_table_all_languages.tex', escape=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5ee5f48e-8921-4ba9-8344-0c5701968517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6r_4f6n16dv6s41vfjb0rqzc0000gn/T/ipykernel_6127/2995602010.py:37: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table.to_latex('correlation_free_table_all_languages.tex', escape=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# Initialize empty lists to store correlations and p-values\n",
    "corr_ortho_list, p_value_ortho_list = [], []\n",
    "corr_phono_list, p_value_phono_list = [], []\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['accuracy_free']\n",
    "    orthographic_distances = df['was_fixed']\n",
    "    phonological_distances = df['pwld_fixed']\n",
    "\n",
    "    # Calculating correlations\n",
    "    corr_ortho, p_value_ortho = pearsonr(orthographic_distances, accuracy_mcq)\n",
    "    corr_phono, p_value_phono = pearsonr(phonological_distances, accuracy_mcq)\n",
    "\n",
    "    # Append results to lists\n",
    "    corr_ortho_list.append(corr_ortho)\n",
    "    p_value_ortho_list.append(p_value_ortho)\n",
    "    corr_phono_list.append(corr_phono)\n",
    "    p_value_phono_list.append(p_value_phono)\n",
    "\n",
    "# Creating a DataFrame with results\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Orthographic Distance': corr_ortho_list,\n",
    "    'Phonological Distance': corr_phono_list,\n",
    "    'p-value (Orthographic)': p_value_ortho_list,\n",
    "    'p-value (Phonological)': p_value_phono_list\n",
    "}, index=list(combined_data.keys()))\n",
    "\n",
    "# Formatting for LaTeX table\n",
    "latex_table = correlation_results.round(3).astype(str)\n",
    "latex_table.to_latex('correlation_free_table_all_languages.tex', escape=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0d6c8-bc15-4576-8819-ee7cfb724601",
   "metadata": {},
   "source": [
    "## Below is correlation with surprisal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3f1ce214-dc03-4b3a-854f-ee2ef1138716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6r_4f6n16dv6s41vfjb0rqzc0000gn/T/ipykernel_6127/1066140477.py:37: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table.to_latex('correlation_table_surprisal_mcq.tex', escape=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Initialize empty lists to store correlations and p-values\n",
    "corr_ortho_list, p_value_ortho_list = [], []\n",
    "corr_phono_list, p_value_phono_list = [], []\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['accuracy_mcq']\n",
    "    orthographic_distances = df['Surprisal Data Wav2vec']\n",
    "    phonological_distances = df['Surprisal Data Whisper']\n",
    "\n",
    "    # Calculating correlations\n",
    "    corr_ortho, p_value_ortho = pearsonr(orthographic_distances, accuracy_mcq)\n",
    "    corr_phono, p_value_phono = pearsonr(phonological_distances, accuracy_mcq)\n",
    "\n",
    "    # Append results to lists\n",
    "    corr_ortho_list.append(corr_ortho)\n",
    "    p_value_ortho_list.append(p_value_ortho)\n",
    "    corr_phono_list.append(corr_phono)\n",
    "    p_value_phono_list.append(p_value_phono)\n",
    "\n",
    "# Creating a DataFrame with results\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Wav2Vec': corr_ortho_list,\n",
    "    'Whisper': corr_phono_list,\n",
    "    'p-value (Wav2Vec)': p_value_ortho_list,\n",
    "    'p-value (Whisper)': p_value_phono_list\n",
    "}, index=list(combined_data.keys()))\n",
    "\n",
    "# Formatting for LaTeX table\n",
    "latex_table = correlation_results.round(3).astype(str)\n",
    "latex_table.to_latex('correlation_table_surprisal_mcq.tex', escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f9ebf-4fa7-43e2-b1bd-c2bf64c8cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# Initialize empty lists to store correlations and p-values\n",
    "corr_ortho_list, p_value_ortho_list = [], []\n",
    "corr_phono_list, p_value_phono_list = [], []\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['accuracy_free']\n",
    "    surprisal_wav2vec = df['Surprisal Data Wav2vec']\n",
    "    surprisal_whisper = df['Surprisal Data Whisper']\n",
    "\n",
    "    # Calculating correlations\n",
    "    corr_w2v, p_value_w2v = pearsonr(surprisal_wav2vec, accuracy_mcq)\n",
    "    corr_whisper, p_value_whisper = pearsonr(surprisal_whisper, accuracy_mcq)\n",
    "\n",
    "    # Append results to lists\n",
    "    corr_ortho_list.append(corr_w2v)\n",
    "    p_value_ortho_list.append(p_value_w2v)\n",
    "    corr_phono_list.append(corr_whisper)\n",
    "    p_value_phono_list.append(p_value_whisper)\n",
    "\n",
    "# Creating a DataFrame with results\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Wav2Vec': corr_ortho_list,\n",
    "    'Whisper': corr_phono_list,\n",
    "    'p-value (Wav2Vec)': p_value_ortho_list,\n",
    "    'p-value (Whisper)': p_value_phono_list\n",
    "}, index=list(combined_data.keys()))\n",
    "\n",
    "# Formatting for LaTeX table\n",
    "latex_table = correlation_results.round(3).astype(str)\n",
    "latex_table.to_latex('correlation_table_surprisal_free.tex', escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "547e8907-1f92-442c-bfe5-2cec5a07f05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/6r_4f6n16dv6s41vfjb0rqzc0000gn/T/ipykernel_6127/1877799434.py:37: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table.to_latex('correlation_table_surprisal_free.tex', escape=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# Initialize empty lists to store correlations and p-values\n",
    "corr_ortho_list, p_value_ortho_list = [], []\n",
    "corr_phono_list, p_value_phono_list = [], []\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['accuracy_free']\n",
    "    orthographic_distances = df['Surprisal Data Wav2vec']\n",
    "    phonological_distances = df['Surprisal Data Whisper']\n",
    "\n",
    "    # Calculating correlations\n",
    "    corr_ortho, p_value_ortho = pearsonr(orthographic_distances, accuracy_mcq)\n",
    "    corr_phono, p_value_phono = pearsonr(phonological_distances, accuracy_mcq)\n",
    "\n",
    "    # Append results to lists\n",
    "    corr_ortho_list.append(corr_ortho)\n",
    "    p_value_ortho_list.append(p_value_ortho)\n",
    "    corr_phono_list.append(corr_phono)\n",
    "    p_value_phono_list.append(p_value_phono)\n",
    "\n",
    "# Creating a DataFrame with results\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Wav2Vec': corr_ortho_list,\n",
    "    'Whisper': corr_phono_list,\n",
    "    'p-value (Wav2Vec)': p_value_ortho_list,\n",
    "    'p-value (Whisper)': p_value_phono_list\n",
    "}, index=list(combined_data.keys()))\n",
    "\n",
    "# Formatting for LaTeX table\n",
    "latex_table = correlation_results.round(3).astype(str)\n",
    "latex_table.to_latex('correlation_table_surprisal_free.tex', escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d2f3b867-3ad6-4360-9091-e2e1f99184ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in combined_data:\n",
    "    combined_data[language] = combined_data[language].dropna(subset=['free_translation_time_correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7a8bd9cd-bea7-4ea5-b0f0-d9b5fdff2458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BE\n",
      "BG\n",
      "CS\n",
      "UK\n",
      "PL\n",
      "    Wav2Vec  Whisper  p-value (Wav2Vec)  p-value (Whisper)\n",
      "BE   -0.344   -0.129              0.009              0.342\n",
      "BG   -0.373   -0.065              0.011              0.666\n",
      "CS   -0.165    0.002              0.301              0.991\n",
      "UK   -0.224   -0.091              0.097              0.506\n",
      "PL   -0.208   -0.029              0.166              0.849\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Initialize empty lists to store correlations and p-values\n",
    "corr_ortho_list, p_value_ortho_list = [], []\n",
    "corr_phono_list, p_value_phono_list = [], []\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    print(language)\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['free_translation_time_correct']\n",
    "    orthographic_distances = df['Surprisal Data Wav2vec']\n",
    "    phonological_distances = df['Surprisal Data Whisper']\n",
    "\n",
    "    # Calculating correlations\n",
    "    corr_ortho, p_value_ortho = pearsonr(orthographic_distances, accuracy_mcq)\n",
    "    corr_phono, p_value_phono = pearsonr(phonological_distances, accuracy_mcq)\n",
    "\n",
    "    # Append results to lists\n",
    "    corr_ortho_list.append(corr_ortho)\n",
    "    p_value_ortho_list.append(p_value_ortho)\n",
    "    corr_phono_list.append(corr_phono)\n",
    "    p_value_phono_list.append(p_value_phono)\n",
    "\n",
    "# Creating a DataFrame with results\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Wav2Vec': corr_ortho_list,\n",
    "    'Whisper': corr_phono_list,\n",
    "    'p-value (Wav2Vec)': p_value_ortho_list,\n",
    "    'p-value (Whisper)': p_value_phono_list\n",
    "}, index=list(combined_data.keys()))\n",
    "\n",
    "# Print the DataFrame instead of saving to LaTeX\n",
    "print(correlation_results.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d5043227-0fbd-4e05-8e1c-d87e410b5d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Wav2Vec  Whisper  p-value (Wav2Vec)  p-value (Whisper)\n",
      "BE   -0.108   -0.015              0.422              0.910\n",
      "BG   -0.215    0.039              0.106              0.772\n",
      "CS    0.029   -0.154              0.828              0.239\n",
      "UK   -0.187    0.137              0.152              0.296\n",
      "PL   -0.085   -0.011              0.526              0.937\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# Initialize empty lists to store correlations and p-values\n",
    "corr_ortho_list, p_value_ortho_list = [], []\n",
    "corr_phono_list, p_value_phono_list = [], []\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['user_mcq_translation_time_taken']\n",
    "    orthographic_distances = df['Surprisal Data Wav2vec']\n",
    "    phonological_distances = df['Surprisal Data Whisper']\n",
    "\n",
    "    # Calculating correlations\n",
    "    corr_ortho, p_value_ortho = pearsonr(orthographic_distances, accuracy_mcq)\n",
    "    corr_phono, p_value_phono = pearsonr(phonological_distances, accuracy_mcq)\n",
    "\n",
    "    # Append results to lists\n",
    "    corr_ortho_list.append(corr_ortho)\n",
    "    p_value_ortho_list.append(p_value_ortho)\n",
    "    corr_phono_list.append(corr_phono)\n",
    "    p_value_phono_list.append(p_value_phono)\n",
    "\n",
    "# Creating a DataFrame with results\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Wav2Vec': corr_ortho_list,\n",
    "    'Whisper': corr_phono_list,\n",
    "    'p-value (Wav2Vec)': p_value_ortho_list,\n",
    "    'p-value (Whisper)': p_value_phono_list\n",
    "}, index=list(combined_data.keys()))\n",
    "\n",
    "# Print the DataFrame instead of saving to LaTeX\n",
    "print(correlation_results.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "13b4660d-b3a4-4164-81ab-f1fc6eb34d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BE\n",
      "all\n",
      "BG\n",
      "CS\n",
      "UK\n",
      "PL\n",
      "       WAS   PWLD  wav2vec  whisper  p-value (WAS)  p-value (pWLD)  \\\n",
      "BE  -0.210 -0.300    0.054    0.427          0.114           0.022   \n",
      "all -0.178 -0.403    0.404    0.223          0.000           0.000   \n",
      "BG  -0.339 -0.445    0.243    0.099          0.009           0.000   \n",
      "CS  -0.006 -0.093    0.009    0.232          0.966           0.479   \n",
      "UK  -0.054 -0.558    0.355    0.120          0.681           0.000   \n",
      "PL  -0.012 -0.284    0.030    0.039          0.929           0.031   \n",
      "\n",
      "     p-value (wav2vec)  p-value (whisper)  \n",
      "BE               0.688              0.001  \n",
      "all              0.000              0.000  \n",
      "BG               0.066              0.458  \n",
      "CS               0.947              0.074  \n",
      "UK               0.005              0.361  \n",
      "PL               0.822              0.773  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# Initialize empty lists to store correlations and p-values\n",
    "corr_ortho_list, p_value_ortho_list = [], []\n",
    "corr_phono_list, p_value_phono_list = [], []\n",
    "\n",
    "corr_wav_list, p_value_wav_list = [], []\n",
    "corr_whisper_list, p_value_whisper_list = [], []\n",
    "\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    print(language)\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['accuracy_free']\n",
    "    orthographic_distances = df['was_fixed']\n",
    "    phonological_distances = df['pwld_fixed']\n",
    "    wav_distances = df['Surprisal Data Wav2vec']\n",
    "    whisper_distances = df['Surprisal Data Whisper']\n",
    "    # Calculating correlations\n",
    "    corr_ortho, p_value_ortho = pearsonr(orthographic_distances, accuracy_mcq)\n",
    "    corr_phono, p_value_phono = pearsonr(phonological_distances, accuracy_mcq)\n",
    "    corr_wav, p_value_wav = pearsonr(wav_distances, accuracy_mcq)\n",
    "    corr_whisper, p_value_whisper = pearsonr(whisper_distances, accuracy_mcq)\n",
    "\n",
    "    # Append results to lists\n",
    "    corr_ortho_list.append(corr_ortho)\n",
    "    p_value_ortho_list.append(p_value_ortho)\n",
    "    corr_phono_list.append(corr_phono)\n",
    "    p_value_phono_list.append(p_value_phono)\n",
    "    corr_wav_list.append(corr_wav)\n",
    "    p_value_wav_list.append(p_value_wav)\n",
    "    corr_whisper_list.append(corr_whisper)\n",
    "    p_value_whisper_list.append(p_value_whisper)\n",
    "\n",
    "# Creating a DataFrame with results\n",
    "correlation_results = pd.DataFrame({\n",
    "    'WAS': corr_ortho_list,\n",
    "    'PWLD': corr_phono_list,\n",
    "    'wav2vec': corr_wav_list,\n",
    "    'whisper': corr_whisper_list,\n",
    "    'p-value (WAS)': p_value_ortho_list,\n",
    "    'p-value (pWLD)': p_value_phono_list,\n",
    "    'p-value (wav2vec)': p_value_wav_list,\n",
    "    'p-value (whisper)': p_value_whisper_list\n",
    "}, index=list(combined_data.keys()))\n",
    "\n",
    "# Print the DataFrame instead of saving to LaTeX\n",
    "print(correlation_results.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9bb0b0bc-ac42-4872-ac50-e3766cdb829f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BE\n",
      "Regression results for BE:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          accuracy_free   R-squared:                       0.239\n",
      "Model:                            OLS   Adj. R-squared:                  0.182\n",
      "Method:                 Least Squares   F-statistic:                     4.168\n",
      "Date:                Wed, 06 Mar 2024   Prob (F-statistic):            0.00522\n",
      "Time:                        14:40:53   Log-Likelihood:                -260.28\n",
      "No. Observations:                  58   AIC:                             530.6\n",
      "Df Residuals:                      53   BIC:                             540.9\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                    -50.5078     69.929     -0.722      0.473    -190.768      89.752\n",
      "was_fixed                 -3.5620      9.989     -0.357      0.723     -23.598      16.474\n",
      "pwld_fixed               -41.1044     26.202     -1.569      0.123     -93.658      11.449\n",
      "Surprisal Data Wav2vec    -0.6417      3.361     -0.191      0.849      -7.383       6.100\n",
      "Surprisal Data Whisper     3.8812      1.226      3.165      0.003       1.421       6.341\n",
      "==============================================================================\n",
      "Omnibus:                        1.540   Durbin-Watson:                   1.533\n",
      "Prob(Omnibus):                  0.463   Jarque-Bera (JB):                1.249\n",
      "Skew:                          -0.158   Prob(JB):                        0.536\n",
      "Kurtosis:                       2.354   Cond. No.                         860.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "all\n",
      "Regression results for all:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          accuracy_free   R-squared:                       0.300\n",
      "Model:                            OLS   Adj. R-squared:                  0.297\n",
      "Method:                 Least Squares   F-statistic:                     93.87\n",
      "Date:                Wed, 06 Mar 2024   Prob (F-statistic):           1.91e-66\n",
      "Time:                        14:40:53   Log-Likelihood:                -4024.8\n",
      "No. Observations:                 880   AIC:                             8060.\n",
      "Df Residuals:                     875   BIC:                             8084.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                    -79.6669     15.447     -5.157      0.000    -109.985     -49.349\n",
      "was_fixed                 -2.5111      2.512     -0.999      0.318      -7.442       2.420\n",
      "pwld_fixed               -60.4679      6.310     -9.583      0.000     -72.852     -48.084\n",
      "Surprisal Data Wav2vec     6.0523      0.512     11.828      0.000       5.048       7.057\n",
      "Surprisal Data Whisper     1.8425      0.329      5.606      0.000       1.197       2.488\n",
      "==============================================================================\n",
      "Omnibus:                       45.601   Durbin-Watson:                   1.830\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.448\n",
      "Skew:                           0.103   Prob(JB):                     5.98e-05\n",
      "Kurtosis:                       2.301   Cond. No.                         708.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "BG\n",
      "Regression results for BG:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          accuracy_free   R-squared:                       0.292\n",
      "Model:                            OLS   Adj. R-squared:                  0.238\n",
      "Method:                 Least Squares   F-statistic:                     5.454\n",
      "Date:                Wed, 06 Mar 2024   Prob (F-statistic):           0.000940\n",
      "Time:                        14:40:53   Log-Likelihood:                -261.19\n",
      "No. Observations:                  58   AIC:                             532.4\n",
      "Df Residuals:                      53   BIC:                             542.7\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     59.5644     65.175      0.914      0.365     -71.160     190.289\n",
      "was_fixed                -24.8905     12.350     -2.015      0.049     -49.661      -0.120\n",
      "pwld_fixed               -61.1963     21.192     -2.888      0.006    -103.702     -18.690\n",
      "Surprisal Data Wav2vec     4.6025      2.609      1.764      0.083      -0.630       9.835\n",
      "Surprisal Data Whisper     0.2285      1.281      0.178      0.859      -2.340       2.797\n",
      "==============================================================================\n",
      "Omnibus:                        3.324   Durbin-Watson:                   2.405\n",
      "Prob(Omnibus):                  0.190   Jarque-Bera (JB):                2.052\n",
      "Skew:                           0.232   Prob(JB):                        0.359\n",
      "Kurtosis:                       2.204   Cond. No.                         807.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "CS\n",
      "Regression results for CS:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          accuracy_free   R-squared:                       0.060\n",
      "Model:                            OLS   Adj. R-squared:                 -0.009\n",
      "Method:                 Least Squares   F-statistic:                    0.8710\n",
      "Date:                Wed, 06 Mar 2024   Prob (F-statistic):              0.487\n",
      "Time:                        14:40:53   Log-Likelihood:                -266.31\n",
      "No. Observations:                  60   AIC:                             542.6\n",
      "Df Residuals:                      55   BIC:                             553.1\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                    -53.7898     50.782     -1.059      0.294    -155.558      47.979\n",
      "was_fixed                  1.0836      8.593      0.126      0.900     -16.137      18.304\n",
      "pwld_fixed               -10.8942     25.011     -0.436      0.665     -61.017      39.229\n",
      "Surprisal Data Wav2vec    -0.8405      2.509     -0.335      0.739      -5.868       4.187\n",
      "Surprisal Data Whisper     2.4790      1.454      1.705      0.094      -0.435       5.393\n",
      "==============================================================================\n",
      "Omnibus:                       14.351   Durbin-Watson:                   2.301\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               16.015\n",
      "Skew:                           1.226   Prob(JB):                     0.000333\n",
      "Kurtosis:                       3.630   Cond. No.                         632.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "UK\n",
      "Regression results for UK:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          accuracy_free   R-squared:                       0.406\n",
      "Model:                            OLS   Adj. R-squared:                  0.363\n",
      "Method:                 Least Squares   F-statistic:                     9.392\n",
      "Date:                Wed, 06 Mar 2024   Prob (F-statistic):           7.37e-06\n",
      "Time:                        14:40:53   Log-Likelihood:                -267.76\n",
      "No. Observations:                  60   AIC:                             545.5\n",
      "Df Residuals:                      55   BIC:                             556.0\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                   -102.3409     85.464     -1.197      0.236    -273.614      68.932\n",
      "was_fixed                 16.2148      7.785      2.083      0.042       0.614      31.815\n",
      "pwld_fixed              -125.6773     25.435     -4.941      0.000    -176.651     -74.704\n",
      "Surprisal Data Wav2vec     7.5646      3.394      2.229      0.030       0.763      14.366\n",
      "Surprisal Data Whisper     0.8584      1.838      0.467      0.642      -2.824       4.541\n",
      "==============================================================================\n",
      "Omnibus:                        3.390   Durbin-Watson:                   2.094\n",
      "Prob(Omnibus):                  0.184   Jarque-Bera (JB):                2.840\n",
      "Skew:                          -0.532   Prob(JB):                        0.242\n",
      "Kurtosis:                       3.075   Cond. No.                     1.13e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.13e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "PL\n",
      "Regression results for PL:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          accuracy_free   R-squared:                       0.087\n",
      "Model:                            OLS   Adj. R-squared:                  0.018\n",
      "Method:                 Least Squares   F-statistic:                     1.268\n",
      "Date:                Wed, 06 Mar 2024   Prob (F-statistic):              0.294\n",
      "Time:                        14:40:53   Log-Likelihood:                -261.43\n",
      "No. Observations:                  58   AIC:                             532.9\n",
      "Df Residuals:                      53   BIC:                             543.2\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      5.8048     69.680      0.083      0.934    -133.955     145.564\n",
      "was_fixed                  0.9360      8.677      0.108      0.915     -16.468      18.340\n",
      "pwld_fixed               -44.6610     20.057     -2.227      0.030     -84.890      -4.432\n",
      "Surprisal Data Wav2vec     1.8067      3.333      0.542      0.590      -4.878       8.491\n",
      "Surprisal Data Whisper     0.2281      1.845      0.124      0.902      -3.473       3.929\n",
      "==============================================================================\n",
      "Omnibus:                        5.887   Durbin-Watson:                   1.697\n",
      "Prob(Omnibus):                  0.053   Jarque-Bera (JB):                5.955\n",
      "Skew:                           0.766   Prob(JB):                       0.0509\n",
      "Kurtosis:                       2.660   Cond. No.                         837.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Assuming combined_data is a dictionary of DataFrames\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    print(language)\n",
    "    # Extracting relevant columns\n",
    "    accuracy_mcq = df['accuracy_free']\n",
    "    independent_variables = df[['was_fixed', 'pwld_fixed', 'Surprisal Data Wav2vec', 'Surprisal Data Whisper']]  # Exclude 'accuracy_free'\n",
    "\n",
    "    # Perform multiple regression\n",
    "    X = sm.add_constant(independent_variables)\n",
    "    model = sm.OLS(accuracy_mcq, X).fit()\n",
    "\n",
    "    # Print the regression summary\n",
    "    print(f'Regression results for {language}:\\n')\n",
    "    print(model.summary())\n",
    "    print('\\n' + '='*80 + '\\n')  # Separating results for different languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "12e3a389-9422-474c-9ecb-47c5f72585e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rllrrr}\n",
      "\\hline\n",
      "    & Language   & Predictor              &   R-squared &   t-value &   p-value \\\\\n",
      "\\hline\n",
      "  0 & BE         & Surprisal Data Whisper &        0.24 &     3.165 &     0.003 \\\\\n",
      "  1 & all        & const                  &        0.3  &    -5.157 &     0     \\\\\n",
      "  2 & all        & pwld_fixed             &        0.3  &    -9.583 &     0     \\\\\n",
      "  3 & all        & Surprisal Data Wav2vec &        0.3  &    11.828 &     0     \\\\\n",
      "  4 & all        & Surprisal Data Whisper &        0.3  &     5.606 &     0     \\\\\n",
      "  5 & BG         & was_fixed              &        0.29 &    -2.015 &     0.049 \\\\\n",
      "  6 & BG         & pwld_fixed             &        0.29 &    -2.888 &     0.006 \\\\\n",
      "  7 & UK         & was_fixed              &        0.41 &     2.083 &     0.042 \\\\\n",
      "  8 & UK         & pwld_fixed             &        0.41 &    -4.941 &     0     \\\\\n",
      "  9 & UK         & Surprisal Data Wav2vec &        0.41 &     2.229 &     0.03  \\\\\n",
      " 10 & PL         & pwld_fixed             &        0.09 &    -2.227 &     0.03  \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Assuming combined_data is a dictionary of DataFrames\n",
    "\n",
    "# Initialize empty lists to store regression results\n",
    "regression_results = []\n",
    "\n",
    "# Iterate over languages\n",
    "for language, df in combined_data.items():\n",
    "    # Extracting relevant columns\n",
    "    dependent_variable = 'accuracy_free'\n",
    "    independent_variables = df[['was_fixed', 'pwld_fixed', 'Surprisal Data Wav2vec', 'Surprisal Data Whisper']]  # Exclude 'accuracy_free'\n",
    "\n",
    "    # Perform multiple regression\n",
    "    predictors = independent_variables.columns\n",
    "    X = sm.add_constant(independent_variables)\n",
    "    model = sm.OLS(df[dependent_variable], X).fit()\n",
    "\n",
    "    # Extract relevant information from the regression results\n",
    "    significant_predictors = model.pvalues[model.pvalues < 0.05].index\n",
    "    for predictor in significant_predictors:\n",
    "        t_value = model.tvalues[predictor]\n",
    "        p_value = model.pvalues[predictor]\n",
    "        r_squared = round(model.rsquared, 2)\n",
    "\n",
    "        # Append results to the list\n",
    "        regression_results.append({\n",
    "            'Language': language,\n",
    "            'Predictor': predictor,\n",
    "            'R-squared': r_squared,\n",
    "            't-value': round(t_value, 3),\n",
    "            'p-value': round(p_value, 3),\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "results_df = pd.DataFrame(regression_results)\n",
    "\n",
    "# Convert the DataFrame to LaTeX format and print\n",
    "latex_table = tabulate(results_df, headers='keys', tablefmt='latex_raw')\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "53c09fd8-43bc-4c7a-a992-290d27e85505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08734735759072854"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debc019-d690-4805-b51f-237e253b180a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
